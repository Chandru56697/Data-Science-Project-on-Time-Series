{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# Download historical stock price data\n",
    "\n",
    "stock_data = yf.download('AAPL', start='2010-01-01', end='2023-01-01')\n",
    "stock_data.to_csv('AAPL_stock_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "* Load the data and handle missing values if any.\n",
    "* Convert the date column to datetime format and set it as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "data = pd.read_csv('AAPL_stock_data.csv')\n",
    "\n",
    "# Convert 'Date' column to datetime format and set as index\n",
    "\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Check for missing values\n",
    "\n",
    "data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "* Visualize the stock price data to understand its trends and patterns.\n",
    "* Check for stationarity using statistical tests like Augmented Dickey-Fuller (ADF) test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the closing prices\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(data['Close'])\n",
    "plt.title('Stock Closing Prices')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.show()\n",
    "\n",
    "# ADF test for stationarity\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "result = adfuller(data['Close'])\n",
    "print('ADF Statistic:', result[0])\n",
    "print('p-value:', result[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation\n",
    "* If the data is not stationary, apply transformations such as differencing or log transformation to make it stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differencing to make the data stationary\n",
    "\n",
    "data['Close_diff'] = data['Close'].diff().dropna()\n",
    "\n",
    "\n",
    "# ADF test on differenced data\n",
    "\n",
    "result_diff = adfuller(data['Close_diff'].dropna())\n",
    "print('ADF Statistic:', result_diff[0])\n",
    "print('p-value:', result_diff[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "* Split the data into training and testing sets.\n",
    "* Use models like ARIMA (AutoRegressive Integrated Moving Average) or LSTM (Long Short-Term Memory) for time series forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ARIMA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_size = int(len(data) * 0.8)\n",
    "train, test = data['Close_diff'].dropna()[:train_size], data['Close_diff'].dropna()[train_size:]\n",
    "\n",
    "\n",
    "# Build and train the ARIMA model\n",
    "model = ARIMA(train, order=(5,1,0))\n",
    "model_fit = model.fit(disp=0)\n",
    "\n",
    "\n",
    "# Forecast\n",
    "forecast = model_fit.forecast(steps=len(test))[0]\n",
    "\n",
    "\n",
    "# Plot forecast vs actual\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(data.index[train_size:], test, label='Actual')\n",
    "plt.plot(data.index[train_size:], forecast, label='Forecast')\n",
    "plt.title('Stock Price Forecast')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "\n",
    "\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_scaled = scaler.fit_transform(data['Close'].values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "# Prepare the dataset for LSTM\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), 0]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "time_step = 100\n",
    "X, Y = create_dataset(data_scaled, time_step)\n",
    "\n",
    "\n",
    "# Split into training and testing sets\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "Y_train, Y_test = Y[:train_size], Y[train_size:]\n",
    "\n",
    "\n",
    "# Reshape input to be [samples, time steps, features] for LSTM\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(time_step, 1)))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, Y_train, batch_size=1, epochs=1)\n",
    "\n",
    "\n",
    "# Predict and scale back the predictions\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "test_predict = scaler.inverse_transform(test_predict)\n",
    "\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(data['Close'], label='Actual')\n",
    "plt.plot(data.index[time_step:len(train_predict)+time_step], train_predict, label='Train Predict')\n",
    "plt.plot(data.index[len(train_predict)+(time_step*2)+1:len(data)-1], test_predict, label='Test Predict')\n",
    "plt.title('Stock Price Prediction')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "* Evaluate the model performance using metrics like Mean Absolute Error (MAE), Mean Squared Error (MSE), or Root Mean Squared Error (RMSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "# Calculate MAE and RMSE\n",
    "mae = mean_absolute_error(test, forecast)\n",
    "rmse = np.sqrt(mean_squared_error(test, forecast))\n",
    "\n",
    "print('Mean Absolute Error:', mae)\n",
    "print('Root Mean Squared Error:', rmse)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
